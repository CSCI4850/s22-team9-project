{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710c676e-c53f-46f3-8127-ed7d934f8236",
   "metadata": {},
   "source": [
    "## Team 9– Alcove: **Music Generation with Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f54b9-77d9-4db1-8b21-648d308b4963",
   "metadata": {},
   "source": [
    "**Group Members:**\n",
    "_Evan Kubick, Louis Lizzadro, Joseph May, Jason Miller, and Emily Musselman_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd311d4d-d94e-4df0-ba5b-df3c9336aa04",
   "metadata": {},
   "source": [
    "For this project, we will develop a recurrent neural network to generate pop music. Specifically, we will use a Long Short-Term Memory (LSTM) network, a type of Recurrent Neural Network that is capable of remembering information for an extended period of time, which is essential for music generation. We will focus on generating a pop melody for our network within a 20-45 second range. As this is an active area of research, several projects will serve as inspiration for building and training our neural network: Google’s Magenta, MuseNet, the AI Jukebox, and Chu et al.’s “Song from PI.”  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e74a45-d794-48e6-b8de-02b806bf82bf",
   "metadata": {},
   "source": [
    "To train our network, we will provide the model with several musical instrument digital interface (MIDI) files as input. The MIDI format is the music industry standard for capturing song data such as what note is played, when the note is pressed and released, the velocity of each note, and so on. MIDI is a powerful tool in music production, as it is essentially sheet music in a computer-recognizable format. Because MIDI files are convenient and Neural Network music generation is an active area of research, several datasets are available for us to leverage and pull to complete our project. For example, the Maestro data set contains piano melodies, the MIDI data set from composing.ai contains a large repository of music and a subset specific to pop music, and a MIDI data set of 50 famous pop songs is available on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90969782-7f8c-4767-9dbe-f47b29173560",
   "metadata": {},
   "source": [
    "Once our model is trained, we can begin to generate music. To do this, we will feed the model a note or a sequence of notes, and then we can iteratively predict each successive note using our trained RNN. These note sequence seeds to our network will be pulled from the Billboard Hot 100 top pop songs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879dbae-b04f-4a55-b15f-ff092995fe1c",
   "metadata": {},
   "source": [
    "To evaluate the quality of our network generated music, we will conduct a single-blind survey of the students in the CSCI 4850/5850 Neural Networks course in which this study is taking place. Participants will be presented with four clips of songs produced by different neural network music generators. The song samples will be generated by Google’s Magenta, the AI Jukebox, Chu et al.’s “Song from PI,” and our proposed neural network. Participants will be asked to listen to each song clip and rank them in order of preference with a ranking of 1 as “most preferred” to 4 “least preferred.” To eliminate bias, the participants of the survey will not know which generator produced which song clip. We will compute the average ranking for each individual network produced song and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460a7a6-f41b-40ef-ab5e-c076805f8ed4",
   "metadata": {},
   "source": [
    "Additionally, to further analyze the music generated by our model, we would like to incorporate our team’s knowledge of music theory into the evaluation criteria. For example, we will evaluate whether our network produced music that captured the regularity of a scale by using the six or seven tone subsets specified by the scale rule. In other words, we will quantify how many “wrong” or “weird” notes appear in the short segment of generated music, based on this theory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
